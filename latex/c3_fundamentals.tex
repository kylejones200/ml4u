\chapter{ML Fundamentals}\label{ch:fundamentals}

\subsection{What You'll Learn}\label{what-youll-learn}

By the end of this chapter, you'll understand three fundamental ML approaches—regression, classification, and clustering—and see how each method maps to specific utility use cases like load forecasting, failure prediction, and customer segmentation. You'll learn to evaluate model performance using appropriate metrics such as MSE, accuracy, and classification reports. Most importantly, you'll recognize when to use supervised versus unsupervised learning, and you'll build practical models using scikit-learn on utility data.


\subsection{The Business Problem: Predicting and Classifying in Complex Environments}\label{the-business-problem-predicting-and-classifying-in-complex-environments}

Utilities operate vast networks of physical assets that must balance supply and demand in real time, making it critical to predict how these systems behave under different conditions. Grid operators must forecast tomorrow's load to schedule generation, maintenance planners must decide which transformers are at greatest risk of failure, and customer engagement teams need to identify which customers are likely to participate in demand response programs.

Traditionally, these tasks have relied on deterministic engineering models or static business rules that work in stable, predictable conditions but struggle in the face of variability and uncertainty. Weather changes hourly, demand fluctuates daily, and aging equipment deteriorates in nonlinear ways. The complexity of modern power systems makes it impractical to encode every rule explicitly or manually sift through massive datasets.

Machine learning addresses this by learning patterns directly from data rather than relying solely on pre-programmed rules. Instead of hand-coding equations to model every scenario, we allow algorithms to find statistical relationships between inputs and outputs. This is particularly powerful in utilities, where data from smart meters, SCADA systems, asset registries, and customer programs contains rich but underutilized signals about system behavior and risks.

Here's what I've learned: you don't need to understand every possible scenario upfront. Let the data tell you what matters.


\subsection{The Analytics Solution: Core Learning Methods}\label{the-analytics-solution-core-learning-methods}

Machine learning is not a single technique but a collection of methods that fall into several broad categories. This chapter focuses on foundational approaches that recur throughout utility applications.

Regression predicts continuous outcomes like future load in megawatts, transformer oil temperature, or customer energy usage. Linear regression can relate temperature and time of day to hourly demand, providing forecasts that help balance supply and demand.

Classification assigns categories—determining whether equipment is healthy or likely to fail, or whether a pattern is normal or anomalous. This underpins predictive maintenance, cybersecurity detection, and many operational workflows.

Clustering groups similar observations together without labels. Clustering smart meter profiles can reveal natural customer segments—those with high evening peaks versus flat daytime usage—informing rate design and demand response targeting.

Understanding these core methods and their differences is essential before tackling more advanced techniques. They provide a common language between data science and engineering teams and form the backbone of most practical machine learning pipelines in utilities.


\subsection{Connecting Methods to Real Utility Scenarios}\label{connecting-methods-to-real-utility-scenarios}

Consider transformer failure prediction. We may have sensor data on temperature, vibration, and load, combined with asset attributes like age and manufacturer. A classification model trained on historical failure records can learn to distinguish healthy transformers from those approaching failure, and by scoring current assets, it flags those at highest risk for inspection or replacement.

For load forecasting, regression models link weather variables, calendar effects, and historical demand patterns to predict consumption at different time horizons, driving market bidding strategies and generator commitment decisions. Even basic models deliver significant operational improvements compared to heuristic forecasts.

In customer analytics, clustering can segment households based on usage profiles from AMI data. These segments inform demand response outreach, such as targeting high-peak households with incentives for load shifting. Clustering can also uncover emerging patterns—like neighborhoods adopting electric vehicles—before they show up in feeder overloading alarms.

These examples illustrate how simple machine learning concepts map directly to real problems. By framing utility questions in terms of prediction, classification, and grouping, we create clear pathways from business needs to analytic solutions.


\subsection{Model Evaluation Primer}\label{model-evaluation-primer}

Before diving into the code, it's important to understand how we assess model quality. For regression, we use Mean Squared Error and R² score. For classification, we use accuracy, precision, recall, and F1-score---especially important when classes are imbalanced, like when failures are rare.

We split data into training and testing sets to detect overfitting. For small datasets, we use k-fold cross-validation to get more reliable performance estimates.


\subsection{When to Use Each Method}\label{when-to-use-each-method}

Use regression for continuous values like load forecasting or temperature prediction. Use classification for categories like failure prediction or anomaly detection. Use clustering to find patterns without labels, like customer segmentation or asset grouping.


\subsection{Building ML Models for Utilities}\label{building-ml-models-for-utilities}

Let's walk through fundamental ML approaches using realistic utility scenarios. Each example is self-contained and shows the complete workflow from data preparation to model evaluation. These are the foundation---everything else builds on them.

\subsubsection{Regression: Temperature to Load}\label{regression-temperature-to-load}

First, we generate regression data and fit a linear model:

\lstinputlisting[firstline=21,lastline=54]{../code/c3_ML4U.py}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{../images/c3_chapter3_regression.png}
\caption{Linear regression model showing temperature vs. load relationship.}
\label{fig:c3_regression}
\end{figure}

This demonstrates how continuous predictions work: the regression line's slope indicates how strongly temperature drives load (e.g., ``each degree Celsius increases load by X MW''), while points scattered far from the line indicate prediction error, which we quantify with MSE. I'm starting with regression because it's simple, interpretable, and often works better than you'd expect.

\subsubsection{Classification: Equipment Failure Prediction}\label{classification-equipment-failure-prediction}

Next, we generate classification data and train a logistic regression model:

\lstinputlisting[firstline=55,lastline=82]{../code/c3_ML4U.py}

This shows how to handle binary classification problems. The classification report displays precision, recall, and F1-score for each class (Healthy vs.~Failure). High precision means few false alarms; high recall means we catch most failures. The balance depends on operational priorities—utilities often prefer higher recall to avoid missing actual failures. I've seen teams get excited about 95\% accuracy, only to realize the model just predicts ``healthy'' for everything. That's why precision and recall matter more than accuracy for imbalanced problems.

\subsubsection{Clustering: Customer Segmentation}\label{clustering-customer-segmentation}

Finally, we group customers by their daily load profiles using K-means:

\lstinputlisting[firstline=83,lastline=110]{../code/c3_ML4U.py}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{../images/c3_chapter3_clustering.png}
\caption{K-means clustering of customer load profiles showing distinct usage segments.}
\label{fig:c3_clustering}
\end{figure}


The complete, runnable script is at \texttt{content/c3/ML4U.py}. Run all three examples and see how they differ.


\subsection{What I Want You to Remember}\label{what-i-want-you-to-remember}

Three methods cover most utility ML needs: regression for continuous predictions, classification for categorical outcomes, and clustering for pattern discovery without labels. Model evaluation is essential—always split data into train/test sets and use appropriate metrics. Overfitting is a constant risk: models that look perfect on training data often fail in production. I've seen this happen too many times: a model that's 99\% accurate on training data but useless in production.

Utility context matters. The same ML technique, such as classification, applies differently to failure prediction versus customer churn, and domain knowledge guides feature selection and interpretation. Start simple, evaluate thoroughly. Linear regression and logistic regression are interpretable and often perform well. Only move to complex models when simple ones prove insufficient. I'm bullish on starting simple—you can always add complexity later, but you can't add interpretability.



\subsection{What's Next}\label{whats-next}

In Chapter 4, we'll dive deeper into time series forecasting—a critical utility application. You'll learn ARIMA models and see how to extend regression approaches to handle temporal dependencies in load forecasting. The principles are the same, but time series adds complexity.
